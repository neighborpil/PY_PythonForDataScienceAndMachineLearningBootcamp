{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00-Keras-Syntax-Basics -1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pb61NtDCFj3H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "MRA8_tAFHJqF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfArKM5WHMdj",
        "outputId": "87965d16-7636-44f0-b551-552c9df98139"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DATA/fake_reg.csv')"
      ],
      "metadata": {
        "id": "hoezActJFp19"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f5ghEUEAGA2O",
        "outputId": "d3b26088-5d6e-49b2-cdab-228f95474092"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        price     feature1     feature2\n",
              "0  461.527929   999.787558   999.766096\n",
              "1  548.130011   998.861615  1001.042403\n",
              "2  410.297162  1000.070267   998.844015\n",
              "3  540.382220   999.952251  1000.440940\n",
              "4  546.024553  1000.446011  1000.338531"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b224b3e-1c77-4e74-a1bb-58418077cfac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>461.527929</td>\n",
              "      <td>999.787558</td>\n",
              "      <td>999.766096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>548.130011</td>\n",
              "      <td>998.861615</td>\n",
              "      <td>1001.042403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>410.297162</td>\n",
              "      <td>1000.070267</td>\n",
              "      <td>998.844015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>540.382220</td>\n",
              "      <td>999.952251</td>\n",
              "      <td>1000.440940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>546.024553</td>\n",
              "      <td>1000.446011</td>\n",
              "      <td>1000.338531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b224b3e-1c77-4e74-a1bb-58418077cfac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b224b3e-1c77-4e74-a1bb-58418077cfac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b224b3e-1c77-4e74-a1bb-58418077cfac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "UGUpS_4GJtpZ",
        "outputId": "4fe7d384-da0a-428e-cbbe-755f0a602b8d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.PairGrid at 0x7f103c7a8bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 540x540 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5-T7cpn5JvIR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['feature1', 'feature2']].values\n",
        "y = df['price'].values"
      ],
      "metadata": {
        "id": "Wq_UzQ-0J2ja"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXpEK3f3J_LD",
        "outputId": "3398e011-5e28-437f-b6b7-ec1c17499c4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 999.78755752,  999.7660962 ],\n",
              "       [ 998.86161491, 1001.04240315],\n",
              "       [1000.07026691,  998.84401463],\n",
              "       ...,\n",
              "       [1001.45164617,  998.84760554],\n",
              "       [1000.77102275,  998.56285086],\n",
              "       [ 999.2322436 , 1001.45140713]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "vyUmvRkYJ_ug"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBskrFjTKHea",
        "outputId": "23e9a0cc-77ba-4232-fc88-c1412298145d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu8uoHeSKJMz",
        "outputId": "15938e50-90e0-4440-ac3b-d4c67f6e7122"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "ZvaeJeDoKKsI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(MinMaxScaler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS5PrkP1KTfD",
        "outputId": "e64d57a6-e085-4413-e642-4dd29f6068c3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class MinMaxScaler in module sklearn.preprocessing._data:\n",
            "\n",
            "class MinMaxScaler(sklearn.base._OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
            " |  MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)\n",
            " |  \n",
            " |  Transform features by scaling each feature to a given range.\n",
            " |  \n",
            " |  This estimator scales and translates each feature individually such\n",
            " |  that it is in the given range on the training set, e.g. between\n",
            " |  zero and one.\n",
            " |  \n",
            " |  The transformation is given by::\n",
            " |  \n",
            " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
            " |      X_scaled = X_std * (max - min) + min\n",
            " |  \n",
            " |  where min, max = feature_range.\n",
            " |  \n",
            " |  This transformation is often used as an alternative to zero mean,\n",
            " |  unit variance scaling.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  feature_range : tuple (min, max), default=(0, 1)\n",
            " |      Desired range of transformed data.\n",
            " |  \n",
            " |  copy : bool, default=True\n",
            " |      Set to False to perform inplace row normalization and avoid a\n",
            " |      copy (if the input is already a numpy array).\n",
            " |  \n",
            " |  clip : bool, default=False\n",
            " |      Set to True to clip transformed values of held-out data to\n",
            " |      provided `feature range`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  min_ : ndarray of shape (n_features,)\n",
            " |      Per feature adjustment for minimum. Equivalent to\n",
            " |      ``min - X.min(axis=0) * self.scale_``\n",
            " |  \n",
            " |  scale_ : ndarray of shape (n_features,)\n",
            " |      Per feature relative scaling of the data. Equivalent to\n",
            " |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *scale_* attribute.\n",
            " |  \n",
            " |  data_min_ : ndarray of shape (n_features,)\n",
            " |      Per feature minimum seen in the data\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *data_min_*\n",
            " |  \n",
            " |  data_max_ : ndarray of shape (n_features,)\n",
            " |      Per feature maximum seen in the data\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *data_max_*\n",
            " |  \n",
            " |  data_range_ : ndarray of shape (n_features,)\n",
            " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *data_range_*\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  n_samples_seen_ : int\n",
            " |      The number of samples processed by the estimator.\n",
            " |      It will be reset on new calls to fit, but increments across\n",
            " |      ``partial_fit`` calls.\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  minmax_scale : Equivalent function without the estimator API.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
            " |  transform.\n",
            " |  \n",
            " |  For a comparison of the different scalers, transformers, and normalizers,\n",
            " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
            " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
            " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
            " |  >>> scaler = MinMaxScaler()\n",
            " |  >>> print(scaler.fit(data))\n",
            " |  MinMaxScaler()\n",
            " |  >>> print(scaler.data_max_)\n",
            " |  [ 1. 18.]\n",
            " |  >>> print(scaler.transform(data))\n",
            " |  [[0.   0.  ]\n",
            " |   [0.25 0.25]\n",
            " |   [0.5  0.5 ]\n",
            " |   [1.   1.  ]]\n",
            " |  >>> print(scaler.transform([[2, 2]]))\n",
            " |  [[1.5 0. ]]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      MinMaxScaler\n",
            " |      sklearn.base._OneToOneFeatureMixin\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, feature_range=(0, 1), *, copy=True, clip=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None)\n",
            " |      Compute the minimum and maximum to be used for later scaling.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          The data used to compute the per-feature minimum and maximum\n",
            " |          used for later scaling along the features axis.\n",
            " |      \n",
            " |      y : None\n",
            " |          Ignored.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted scaler.\n",
            " |  \n",
            " |  inverse_transform(self, X)\n",
            " |      Undo the scaling of X according to feature_range.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data that will be transformed. It cannot be sparse.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : ndarray of shape (n_samples, n_features)\n",
            " |          Transformed data.\n",
            " |  \n",
            " |  partial_fit(self, X, y=None)\n",
            " |      Online computation of min and max on X for later scaling.\n",
            " |      \n",
            " |      All of X is processed as a single batch. This is intended for cases\n",
            " |      when :meth:`fit` is not feasible due to very large number of\n",
            " |      `n_samples` or because X is read from a continuous stream.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          The data used to compute the mean and standard deviation\n",
            " |          used for later scaling along the features axis.\n",
            " |      \n",
            " |      y : None\n",
            " |          Ignored.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted scaler.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Scale features of X according to feature_range.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data that will be transformed.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : ndarray of shape (n_samples, n_features)\n",
            " |          Transformed data.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base._OneToOneFeatureMixin:\n",
            " |  \n",
            " |  get_feature_names_out(self, input_features=None)\n",
            " |      Get output feature names for transformation.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      input_features : array-like of str or None, default=None\n",
            " |          Input features.\n",
            " |      \n",
            " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
            " |            used as feature names in. If `feature_names_in_` is not defined,\n",
            " |            then names are generated: `[x0, x1, ..., x(n_features_in_)]`.\n",
            " |          - If `input_features` is an array-like, then `input_features` must\n",
            " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_names_out : ndarray of str objects\n",
            " |          Same as input features.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base._OneToOneFeatureMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  fit_transform(self, X, y=None, **fit_params)\n",
            " |      Fit to data, then transform it.\n",
            " |      \n",
            " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
            " |      and returns a transformed version of `X`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input samples.\n",
            " |      \n",
            " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
            " |          Target values (None for unsupervised transformations).\n",
            " |      \n",
            " |      **fit_params : dict\n",
            " |          Additional fit parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
            " |          Transformed array.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "U7kTlJwBKVU6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VenNEC8KbaK",
        "outputId": "0a381f46-5a2d-408b-ab78-a7c6e74f730f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaler.transform(X_train)"
      ],
      "metadata": {
        "id": "8I6mMIWIKdK7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "dA98j1l6KiCb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4BT4vMIKlNS",
        "outputId": "4b8bb62e-7e64-44e8-dd22-c9c5b4b5afd2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF5ASoWcKm7z",
        "outputId": "c1abad4c-d415-410b-e55a-4fb6e57e6f2e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "Y8N2Lt6AKoE4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(Sequential)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL2UwrbfKvEb",
        "outputId": "92a4f3ab-85eb-4df2-ce9b-f0f3b5e6008c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Sequential in module keras.engine.sequential:\n",
            "\n",
            "class Sequential(keras.engine.functional.Functional)\n",
            " |  Sequential(*args, **kwargs)\n",
            " |  \n",
            " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
            " |  \n",
            " |  `Sequential` provides training and inference features on this model.\n",
            " |  \n",
            " |  Examples:\n",
            " |  \n",
            " |  ```python\n",
            " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  # Afterwards, we do automatic shape inference:\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  \n",
            " |  # This is identical to the following:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.Input(shape=(16,)))\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  \n",
            " |  # Note that you can also omit the `input_shape` argument.\n",
            " |  # In that case the model doesn't have any weights until the first call\n",
            " |  # to a training/evaluation method (since it isn't yet built):\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  # model.weights not created yet\n",
            " |  \n",
            " |  # Whereas if you specify the input shape, the model gets built\n",
            " |  # continuously as you are adding layers:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  len(model.weights)\n",
            " |  # Returns \"4\"\n",
            " |  \n",
            " |  # When using the delayed-build pattern (no input shape specified), you can\n",
            " |  # choose to manually build your model by calling\n",
            " |  # `build(batch_input_shape)`:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  model.build((None, 16))\n",
            " |  len(model.weights)\n",
            " |  # Returns \"4\"\n",
            " |  \n",
            " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
            " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
            " |  # or the first time you call the model on some input data.\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(1))\n",
            " |  model.compile(optimizer='sgd', loss='mse')\n",
            " |  # This builds the model for the first time:\n",
            " |  model.fit(x, y, batch_size=32, epochs=10)\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Sequential\n",
            " |      keras.engine.functional.Functional\n",
            " |      keras.engine.training.Model\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      keras.utils.version_utils.ModelVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, layers=None, name=None)\n",
            " |      Creates a `Sequential` model instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        layers: Optional list of layers to add to the model.\n",
            " |        name: Optional name for the model.\n",
            " |  \n",
            " |  add(self, layer)\n",
            " |      Adds a layer instance on top of the layer stack.\n",
            " |      \n",
            " |      Args:\n",
            " |          layer: layer instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: If `layer` is not a layer instance.\n",
            " |          ValueError: In case the `layer` argument does not\n",
            " |              know its input shape.\n",
            " |          ValueError: In case the `layer` argument has\n",
            " |              multiple output tensors, or is already connected\n",
            " |              somewhere else (forbidden in `Sequential` models).\n",
            " |  \n",
            " |  build(self, input_shape=None)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at instantiation\n",
            " |      time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of shapes,\n",
            " |         where shapes are tuples, integers, or `TensorShape` instances.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, `TensorShape`, or dict).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or keyword arg in call signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling it\n",
            " |        on real tensor data.\n",
            " |  \n",
            " |  call(self, inputs, training=None, mask=None)\n",
            " |      Calls the model on new inputs.\n",
            " |      \n",
            " |      In this case `call` just reapplies\n",
            " |      all ops in the graph to the new inputs\n",
            " |      (e.g. build a new computational graph from the provided inputs).\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: A tensor or list of tensors.\n",
            " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
            " |            the `Network` in training mode or inference mode.\n",
            " |          mask: A mask or list of masks. A mask can be\n",
            " |              either a tensor or None (no mask).\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor if there is a single output, or\n",
            " |          a list of tensors if there are more than one outputs.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      This method will cause the layer's state to be built, if that has not\n",
            " |      happened before. This requires that the layer will later be used with\n",
            " |      inputs that match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
            " |      every time it is called. The callers should make a copy of the returned dict\n",
            " |      if they want to modify it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  pop(self)\n",
            " |      Removes the last layer in the model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: if there are no layers in the model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Instantiates a Model from its config (output of `get_config()`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Model config dictionary.\n",
            " |          custom_objects: Optional dictionary mapping names\n",
            " |              (strings) to custom classes or functions to be\n",
            " |              considered during deserialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A model instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of improperly formatted config dict.\n",
            " |          TypeError: In case the config does match the cls constructor.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.functional.Functional:\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __copy__(self)\n",
            " |  \n",
            " |  __deepcopy__(self, memo)\n",
            " |  \n",
            " |  __reduce__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
            " |                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
            " |                    metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
            " |                             tf.keras.metrics.FalseNegatives()])\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            " |            `tf.keras.optimizers`.\n",
            " |          loss: Loss function. Maybe be a string (name of loss function), or\n",
            " |            a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
            " |            function is any callable with the signature `loss = fn(y_true,\n",
            " |            y_pred)`, where `y_true` are the ground truth values, and\n",
            " |            `y_pred` are the model's predictions.\n",
            " |            `y_true` should have shape\n",
            " |            `(batch_size, d0, .. dN)` (except in the case of\n",
            " |            sparse loss functions such as\n",
            " |            sparse categorical crossentropy which expects integer arrays of shape\n",
            " |            `(batch_size, d0, .. dN-1)`).\n",
            " |            `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
            " |            The loss function should return a float tensor.\n",
            " |            If a custom `Loss` instance is\n",
            " |            used and reduction is set to `None`, return value has shape\n",
            " |            `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
            " |            values; otherwise, it is a scalar. If the model has multiple outputs,\n",
            " |            you can use a different loss on each output by passing a dictionary\n",
            " |            or a list of losses. The loss value that will be minimized by the\n",
            " |            model will then be the sum of all individual losses, unless\n",
            " |            `loss_weights` is specified.\n",
            " |          metrics: List of metrics to be evaluated by the model during training\n",
            " |            and testing. Each of this can be a string (name of a built-in\n",
            " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
            " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
            " |            function is any callable with the signature `result = fn(y_true,\n",
            " |            y_pred)`. To specify different metrics for different outputs of a\n",
            " |            multi-output model, you could also pass a dictionary, such as\n",
            " |            `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
            " |            You can also pass a list to specify a metric or a list of metrics\n",
            " |            for each output, such as `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
            " |            or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            " |            strings 'accuracy' or 'acc', we convert this to one of\n",
            " |            `tf.keras.metrics.BinaryAccuracy`,\n",
            " |            `tf.keras.metrics.CategoricalAccuracy`,\n",
            " |            `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
            " |            function used and the model output shape. We do a similar\n",
            " |            conversion for the strings 'crossentropy' and 'ce' as well.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
            " |            (Python floats) to weight the loss contributions of different model\n",
            " |            outputs. The loss value that will be minimized by the model will then\n",
            " |            be the *weighted sum* of all individual losses, weighted by the\n",
            " |            `loss_weights` coefficients.\n",
            " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
            " |                outputs. If a dict, it is expected to map output names (strings)\n",
            " |                to scalar coefficients.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |            `sample_weight` or `class_weight` during training and testing.\n",
            " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
            " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
            " |            this as `None` unless your `Model` cannot be run inside a\n",
            " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          steps_per_execution: Int. Defaults to 1. The number of batches to run\n",
            " |            during each `tf.function` call. Running multiple batches inside a\n",
            " |            single `tf.function` call can greatly improve performance on TPUs or\n",
            " |            small models with a large Python overhead. At most, one full epoch\n",
            " |            will be run each execution. If a number larger than the size of the\n",
            " |            epoch is passed, the execution will be truncated to the size of the\n",
            " |            epoch. Note that if `steps_per_execution` is set to `N`,\n",
            " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods will\n",
            " |            only be called every `N` batches (i.e. before/after each `tf.function`\n",
            " |            execution).\n",
            " |          jit_compile: If `True`, compile the model training step with XLA.\n",
            " |            [XLA](https://www.tensorflow.org/xla) is an optimizing compiler for\n",
            " |            machine learning.\n",
            " |            `jit_compile` is not enabled for by default.\n",
            " |            This option cannot be enabled with `run_eagerly=True`.\n",
            " |            Note that `jit_compile=True` is\n",
            " |            may not necessarily work for all models.\n",
            " |            For more information on supported operations please refer to the\n",
            " |            [XLA documentation](https://www.tensorflow.org/xla).\n",
            " |            Also refer to\n",
            " |            [known XLA issues](https://www.tensorflow.org/xla/known_issues) for\n",
            " |            more details.\n",
            " |          **kwargs: Arguments supported for backwards compatibility only.\n",
            " |  \n",
            " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
            " |      Compute the total loss, validate it, and return it.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom loss\n",
            " |      computation logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, *args, **kwargs):\n",
            " |          super(MyModel, self).__init__(*args, **kwargs)\n",
            " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
            " |      \n",
            " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
            " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
            " |          loss += tf.add_n(self.losses)\n",
            " |          self.loss_tracker.update_state(loss)\n",
            " |          return loss\n",
            " |      \n",
            " |        def reset_metrics(self):\n",
            " |          self.loss_tracker.reset_states()\n",
            " |      \n",
            " |        @property\n",
            " |        def metrics(self):\n",
            " |          return [self.loss_tracker]\n",
            " |      \n",
            " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
            " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
            " |      \n",
            " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
            " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
            " |      model = MyModel(inputs, outputs)\n",
            " |      model.add_loss(tf.reduce_sum(outputs))\n",
            " |      \n",
            " |      optimizer = tf.keras.optimizers.SGD()\n",
            " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
            " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
            " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which is\n",
            " |        the case when called by `Model.test_step`).\n",
            " |  \n",
            " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
            " |      Update metric states and collect all metrics to be returned.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom metric\n",
            " |      updating and collection logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Sequential):\n",
            " |      \n",
            " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
            " |      \n",
            " |          # This super call updates `self.compiled_metrics` and returns results\n",
            " |          # for all metrics listed in `self.metrics`.\n",
            " |          metric_results = super(MyModel, self).compute_metrics(\n",
            " |              x, y, y_pred, sample_weight)\n",
            " |      \n",
            " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
            " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
            " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
            " |          return metric_results\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
            " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            " |            should not be specified (since targets will be obtained from the\n",
            " |            iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
            " |            specify the `batch_size` if your data is in the form of a dataset,\n",
            " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
            " |            batches).\n",
            " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat (1D)\n",
            " |            Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every timestep\n",
            " |                of every sample. This argument is not supported when `x` is a\n",
            " |                dataset, instead pass sample weights as the third element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |            input only. Maximum size for the generator queue. If unspecified,\n",
            " |            `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using process-based\n",
            " |            threading. If unspecified, `workers` will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-picklable arguments to the\n",
            " |            generator as they can't be passed easily to children processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |          **kwargs: Unused at this time.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
            " |              callable that takes a single argument of type\n",
            " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
            " |              `DatasetCreator` should be used when users prefer to specify the\n",
            " |              per-replica batching and sharding logic for the `Dataset`.\n",
            " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
            " |              information.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given below. If using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
            " |            `DatasetCreator` type is supported for `x`.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            " |            or `keras.utils.Sequence` instance, `y` should\n",
            " |            not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided\n",
            " |              (unless the `steps_per_epoch` flag is set to\n",
            " |              something other than None).\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so verbose=2 is\n",
            " |              recommended when not running interactively (eg, in a production\n",
            " |              environment).\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
            " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
            " |              and need not be passed into `model.fit`.\n",
            " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
            " |              `verbose` argument to `model.fit`.\n",
            " |              Callbacks with batch-level calls are currently unsupported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`, and users are\n",
            " |              advised to implement epoch-level calls instead with an appropriate\n",
            " |              `steps_per_epoch` value.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
            " |              not supported when `x` is a dataset, generator or\n",
            " |             `keras.utils.Sequence` instance.\n",
            " |              `validation_split` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data. Thus, note the fact\n",
            " |              that the validation loss of data provided using `validation_split`\n",
            " |              or `validation_data` is not affected by regularization layers like\n",
            " |              noise and dropout.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_data` could be:\n",
            " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
            " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.\n",
            " |                - A `tf.data.Dataset`.\n",
            " |                - A Python generator or `keras.utils.Sequence` returning\n",
            " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
            " |              `validation_data` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          shuffle: Boolean (whether to shuffle the training data\n",
            " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
            " |              when `x` is a generator or an object of tf.data.Dataset.\n",
            " |              'batch' is a special option for dealing\n",
            " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class.\n",
            " |          sample_weight: Optional Numpy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample. This\n",
            " |              argument is not supported when `x` is a dataset, generator, or\n",
            " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
            " |              as the third element of `x`.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps_per_epoch'\n",
            " |              is None, the epoch will run until the input dataset is exhausted.\n",
            " |              When passing an infinitely repeating dataset, you must specify the\n",
            " |              `steps_per_epoch` argument. If `steps_per_epoch=-1` the training\n",
            " |              will run indefinitely with an infinitely repeating dataset.\n",
            " |              This argument is not supported with array inputs.\n",
            " |              When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
            " |                * `steps_per_epoch=None` is not supported.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided and\n",
            " |              is a `tf.data` dataset. Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
            " |              will run until the `validation_data` dataset is exhausted. In the\n",
            " |              case of an infinitely repeated dataset, it will run into an\n",
            " |              infinite loop. If 'validation_steps' is specified and only part of\n",
            " |              the dataset will be consumed, the evaluation will start from the\n",
            " |              beginning of the dataset at each epoch. This ensures that the same\n",
            " |              validation samples are used every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided. Integer\n",
            " |              or `collections.abc.Container` instance (e.g. list, tuple, etc.).\n",
            " |              If an integer, specifies how many training epochs to run before a\n",
            " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
            " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
            " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
            " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up\n",
            " |              when using process-based threading. If unspecified, `workers`\n",
            " |              will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
            " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
            " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
            " |        second and third elements will be used for y and sample_weight\n",
            " |        respectively. Any other type provided will be wrapped in a length one\n",
            " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
            " |        should still adhere to the top-level tuple structure.\n",
            " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |        features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the namedtuple. The reason is that\n",
            " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |        datatype (dict). So given a namedtuple of the form:\n",
            " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |        it is ambiguous whether to reverse the order of the elements when\n",
            " |        interpreting the value. Even worse is a tuple of the form:\n",
            " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
            " |        and sample_weight or passed through as a single element to `x`. As a\n",
            " |        result the data processing code will simply raise a ValueError if it\n",
            " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: 1. If the model was never compiled or,\n",
            " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            " |      \n",
            " |          ValueError: In case of mismatch between the provided input data\n",
            " |              and what the model expects or when the input data is empty.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            " |        this endpoint.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Args:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
            " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
            " |      \n",
            " |      If `by_name` is False weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the weights\n",
            " |      were saved.  Note that layers that don't have weights are not taken into\n",
            " |      account in the topological ordering, so adding or removing layers is fine as\n",
            " |      long as they don't have weights.\n",
            " |      \n",
            " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
            " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
            " |      some of the layers have changed.\n",
            " |      \n",
            " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
            " |      from the TensorFlow format. Note that topological loading differs slightly\n",
            " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
            " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
            " |      TensorFlow format loads based on the object-local names of attributes to\n",
            " |      which layers are assigned in the `Model`'s constructor.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, path to the weights file to load. For weight files in\n",
            " |              TensorFlow format, this is the file prefix (the same as was passed\n",
            " |              to `save_weights`). This can also be a path to a SavedModel\n",
            " |              saved from `model.save`.\n",
            " |          by_name: Boolean, whether to load weights by name or by topological\n",
            " |              order. Only topological loading is supported for weight files in\n",
            " |              TensorFlow format.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
            " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
            " |              the weight (only valid when `by_name=True`).\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for loading weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          When loading a weight file in TensorFlow format, returns the same status\n",
            " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
            " |          ops are run automatically as soon as the network is built (on first call\n",
            " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
            " |          already built).\n",
            " |      \n",
            " |          When loading weights in HDF5 format, returns `None`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available and the weight file is in HDF5\n",
            " |              format.\n",
            " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
            " |            `False`.\n",
            " |  \n",
            " |  make_predict_function(self, force=False)\n",
            " |      Creates a function that executes one step of inference.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.predict_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.predict` or\n",
            " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the predict function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            " |  \n",
            " |  make_test_function(self, force=False)\n",
            " |      Creates a function that executes one step of evaluation.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.test_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.evaluate` or\n",
            " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the test function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            " |  \n",
            " |  make_train_function(self, force=False)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the train function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for batch processing\n",
            " |      of large numbers of inputs. It is not intended for use inside of loops\n",
            " |      that iterate over your data and process small numbers of inputs at a time.\n",
            " |      \n",
            " |      For small numbers of inputs that fit in one batch,\n",
            " |      directly use `__call__()` for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
            " |      inference. You may pair the individual model call with a `tf.function`\n",
            " |      for additional performance inside your inner loop.\n",
            " |      If you need access to numpy array values instead of tensors after your\n",
            " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
            " |      an eager tensor.\n",
            " |      \n",
            " |      Also, note the fact that test loss is not affected by\n",
            " |      regularization layers like noise and dropout.\n",
            " |      \n",
            " |      Note: See [this FAQ entry](\n",
            " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
            " |      for more details about the difference between `Model` methods `predict()`\n",
            " |      and `__call__()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: Verbosity mode, 0 or 1.\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict()` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            " |      three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of inference.\n",
            " |      This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of all the metrics in the model.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            " |      \n",
            " |      >>> model.reset_metrics()\n",
            " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
            " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
            " |      \n",
            " |      Please see `tf.keras.models.save_model` or the\n",
            " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
            " |      for details.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
            " |              model.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          include_optimizer: If True, save optimizer's state together.\n",
            " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
            " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
            " |              and 'h5' in TF 1.X.\n",
            " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
            " |              'tf' format only. Please see the `signatures` argument in\n",
            " |              `tf.saved_model.save` for details.\n",
            " |          options: (only applies to SavedModel format)\n",
            " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
            " |              saving to SavedModel.\n",
            " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
            " |              SavedModel will store the function traces for each layer. This\n",
            " |              can be disabled, so that only the configs of each layer are stored.\n",
            " |              Defaults to `True`. Disabling this will decrease serialization time\n",
            " |              and reduce file size, but it requires that all custom layers/models\n",
            " |              implement a `get_config()` method.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      from keras.models import load_model\n",
            " |      \n",
            " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
            " |      del model  # deletes the existing model\n",
            " |      \n",
            " |      # returns a compiled model\n",
            " |      # identical to the previous one\n",
            " |      model = load_model('my_model.h5')\n",
            " |      ```\n",
            " |  \n",
            " |  save_spec(self, dynamic_batch=True)\n",
            " |      Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n",
            " |      \n",
            " |      This value is automatically defined after calling the model for the first\n",
            " |      time. Afterwards, you can use it when exporting the model for serving:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Model(...)\n",
            " |      \n",
            " |      @tf.function\n",
            " |      def serve(*args, **kwargs):\n",
            " |        outputs = model(*args, **kwargs)\n",
            " |        # Apply postprocessing steps, or add additional outputs.\n",
            " |        ...\n",
            " |        return outputs\n",
            " |      \n",
            " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is\n",
            " |      # an empty dict since functional models do not use keyword arguments.\n",
            " |      arg_specs, kwarg_specs = model.save_spec()\n",
            " |      \n",
            " |      model.save(path, signatures={\n",
            " |        'serving_default': serve.get_concrete_function(*arg_specs, **kwarg_specs)\n",
            " |      })\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
            " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
            " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
            " |          batch size will always be preserved). Defaults to `True`.\n",
            " |      Returns:\n",
            " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
            " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
            " |        If the model inputs are not defined, returns `None`.\n",
            " |        The model inputs are automatically set when calling the model,\n",
            " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network are\n",
            " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            " |      instances or `Optimizer` instances assigned to object attributes. For\n",
            " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            " |      `Layer` instances must be assigned to object attributes, typically in the\n",
            " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            " |      `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a root\n",
            " |      object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            " |      the `Model`'s variables. See the\n",
            " |      [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)\n",
            " |      for details on the TensorFlow format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String or PathLike, path to the file to save the weights to.\n",
            " |              When saving in TensorFlow format, this is the prefix used for\n",
            " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
            " |              suffix causes weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            " |              `None` defaults to 'tf'.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for saving weights.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available when attempting to save in HDF5\n",
            " |              format.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Args:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided,\n",
            " |              defaults to `[.33, .55, .67, 1.]`.\n",
            " |          print_fn: Print function to use. Defaults to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |          expand_nested: Whether to expand the nested models.\n",
            " |              If not provided, defaults to `False`.\n",
            " |          show_trainable: Whether to show if a layer is trainable.\n",
            " |              If not provided, defaults to `False`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors, if\n",
            " |                the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathematical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
            " |      RuntimeError.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: announces that the method poses a security risk\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            " |            weight (float) to apply to the model's loss for the samples from this\n",
            " |            class during training. This can be useful to tell the model to \"pay\n",
            " |            more attention\" to samples from an under-represented class.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      The logic for one training step.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      For concrete examples of how to override this method see\n",
            " |      [Customizing what happends in fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
            " |      This method is called by `Model.make_train_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of training.\n",
            " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
            " |      and metric updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_train_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  metrics\n",
            " |      Returns the model's metrics added using `compile()`, `add_metric()` APIs.\n",
            " |      \n",
            " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
            " |      has been trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become easier\n",
            " |      for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Args:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |        - If the layer is not built, the method will call `build`.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |            inputs - Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after updating\n",
            " |      a layer weights. It can be overridden to finalize any additional layer state\n",
            " |      after a weight update.\n",
            " |      \n",
            " |      This function will be called after weights of a layer have been restored\n",
            " |      from a loaded model.\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(Dense)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdFnfENTLBMD",
        "outputId": "b05eff67-3647-4364-cfb0-bd091fa60e38"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Dense in module keras.layers.core.dense:\n",
            "\n",
            "class Dense(keras.engine.base_layer.Layer)\n",
            " |  Dense(*args, **kwargs)\n",
            " |  \n",
            " |  Just your regular densely-connected NN layer.\n",
            " |  \n",
            " |  `Dense` implements the operation:\n",
            " |  `output = activation(dot(input, kernel) + bias)`\n",
            " |  where `activation` is the element-wise activation function\n",
            " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
            " |  created by the layer, and `bias` is a bias vector created by the layer\n",
            " |  (only applicable if `use_bias` is `True`). These are all attributes of\n",
            " |  `Dense`.\n",
            " |  \n",
            " |  Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
            " |  computes the dot product between the `inputs` and the `kernel` along the\n",
            " |  last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
            " |  For example, if input has dimensions `(batch_size, d0, d1)`,\n",
            " |  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
            " |  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
            " |  (there are `batch_size * d0` such sub-tensors).\n",
            " |  The output in this case will have shape `(batch_size, d0, units)`.\n",
            " |  \n",
            " |  Besides, layer attributes cannot be modified after the layer has been called\n",
            " |  once (except the `trainable` attribute).\n",
            " |  When a popular kwarg `input_shape` is passed, then keras will create\n",
            " |  an input layer to insert before the current layer. This can be treated\n",
            " |  equivalent to explicitly defining an `InputLayer`.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
            " |  >>> model = tf.keras.models.Sequential()\n",
            " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
            " |  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
            " |  >>> # Now the model will take as input arrays of shape (None, 16)\n",
            " |  >>> # and output arrays of shape (None, 32).\n",
            " |  >>> # Note that after the first layer, you don't need to specify\n",
            " |  >>> # the size of the input anymore:\n",
            " |  >>> model.add(tf.keras.layers.Dense(32))\n",
            " |  >>> model.output_shape\n",
            " |  (None, 32)\n",
            " |  \n",
            " |  Args:\n",
            " |    units: Positive integer, dimensionality of the output space.\n",
            " |    activation: Activation function to use.\n",
            " |      If you don't specify anything, no activation is applied\n",
            " |      (ie. \"linear\" activation: `a(x) = x`).\n",
            " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
            " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
            " |    bias_initializer: Initializer for the bias vector.\n",
            " |    kernel_regularizer: Regularizer function applied to\n",
            " |      the `kernel` weights matrix.\n",
            " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
            " |    activity_regularizer: Regularizer function applied to\n",
            " |      the output of the layer (its \"activation\").\n",
            " |    kernel_constraint: Constraint function applied to\n",
            " |      the `kernel` weights matrix.\n",
            " |    bias_constraint: Constraint function applied to the bias vector.\n",
            " |  \n",
            " |  Input shape:\n",
            " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
            " |    The most common situation would be\n",
            " |    a 2D input with shape `(batch_size, input_dim)`.\n",
            " |  \n",
            " |  Output shape:\n",
            " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
            " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
            " |    the output would have shape `(batch_size, units)`.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Dense\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |      Creates the variables of the layer (optional, for subclass implementers).\n",
            " |      \n",
            " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
            " |      can override if they need a state-creation step in-between\n",
            " |      layer instantiation and layer call. It is invoked automatically before\n",
            " |      the first execution of `call()`.\n",
            " |      \n",
            " |      This is typically used to create the weights of `Layer` subclasses\n",
            " |      (at the discretion of the subclass implementer).\n",
            " |      \n",
            " |      Args:\n",
            " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
            " |          `TensorShape` if the layer expects a list of inputs\n",
            " |          (one instance per input).\n",
            " |  \n",
            " |  call(self, inputs)\n",
            " |      This is where the layer's logic lives.\n",
            " |      \n",
            " |      The `call()` method may not create state (except in its first invocation,\n",
            " |      wrapping the creation of variables or other resources in `tf.init_scope()`).\n",
            " |      It is recommended to create state in `__init__()`, or the `build()` method\n",
            " |      that is called automatically before `call()` executes the first time.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
            " |          The first positional `inputs` argument is subject to special rules:\n",
            " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
            " |            arguments, and `inputs` cannot be provided via the default value\n",
            " |            of a keyword argument.\n",
            " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
            " |          - Keras mask metadata is only collected from `inputs`.\n",
            " |          - Layers are built (`build(input_shape)` method)\n",
            " |            using shape info from `inputs` only.\n",
            " |          - `input_spec` compatibility is only checked against `inputs`.\n",
            " |          - Mixed precision input casting is only applied to `inputs`.\n",
            " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
            " |            casting behavior in mixed precision should be handled manually.\n",
            " |          - The SavedModel input specification is generated using `inputs` only.\n",
            " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
            " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
            " |            positional and keyword arguments.\n",
            " |        *args: Additional positional arguments. May contain tensors, although\n",
            " |          this is not recommended, for the reasons above.\n",
            " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
            " |          this is not recommended, for the reasons above.\n",
            " |          The following optional keyword arguments are reserved:\n",
            " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
            " |            `mask` argument, its default value will be set to the mask generated\n",
            " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
            " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
            " |            layer with masking support).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A tensor or list/tuple of tensors.\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      This method will cause the layer's state to be built, if that has not\n",
            " |      happened before. This requires that the layer will later be used with\n",
            " |      inputs that match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
            " |      every time it is called. The callers should make a copy of the returned dict\n",
            " |      if they want to modify it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Args:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |        - If the layer is not built, the method will call `build`.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |            inputs - Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask=None)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after updating\n",
            " |      a layer weights. It can be overridden to finalize any additional layer state\n",
            " |      after a weight update.\n",
            " |      \n",
            " |      This function will be called after weights of a layer have been restored\n",
            " |      from a loaded model.\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Returns the current weights of the layer, as NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      returns both trainable and non-trainable weight values associated with this\n",
            " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
            " |      into similarly parameterized layers.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Returns:\n",
            " |          Weights values as a list of NumPy arrays.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  from_config(config) from builtins.type\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  metrics\n",
            " |      List of metrics added using the `add_metric()` API.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2)\n",
            " |      >>> output = d(input)\n",
            " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
            " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
            " |      >>> [m.name for m in d.metrics]\n",
            " |      ['max', 'min']\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of `Metric` objects.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([Dense(4, activation='relu'),\n",
        "                    Dense(2, activation='relu'),\n",
        "                    Dense(1)])"
      ],
      "metadata": {
        "id": "JLZODp3ALFqg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same as upper box\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='mse')"
      ],
      "metadata": {
        "id": "_empfOK7LsIJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y=y_train, epochs=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijcAmKNWL3vR",
        "outputId": "b13457a2-354a-416d-f545-f05d27c3c073"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "22/22 [==============================] - 1s 3ms/step - loss: 256306.3281\n",
            "Epoch 2/250\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 256046.0781\n",
            "Epoch 3/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 255799.8125\n",
            "Epoch 4/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 255535.0000\n",
            "Epoch 5/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 255239.1094\n",
            "Epoch 6/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 254909.0781\n",
            "Epoch 7/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 254540.8906\n",
            "Epoch 8/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 254130.0625\n",
            "Epoch 9/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 253667.5938\n",
            "Epoch 10/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 253149.6719\n",
            "Epoch 11/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 252571.9062\n",
            "Epoch 12/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 251932.8281\n",
            "Epoch 13/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 251225.6719\n",
            "Epoch 14/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 250449.4688\n",
            "Epoch 15/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 249597.6719\n",
            "Epoch 16/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 248668.5781\n",
            "Epoch 17/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 247656.0625\n",
            "Epoch 18/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 246556.3438\n",
            "Epoch 19/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 245363.2500\n",
            "Epoch 20/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 244073.4375\n",
            "Epoch 21/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 242679.7969\n",
            "Epoch 22/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 241175.9844\n",
            "Epoch 23/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 239542.3125\n",
            "Epoch 24/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 237792.6406\n",
            "Epoch 25/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 235899.3438\n",
            "Epoch 26/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 233857.7188\n",
            "Epoch 27/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 231672.7500\n",
            "Epoch 28/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 229326.8125\n",
            "Epoch 29/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 226824.7031\n",
            "Epoch 30/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 224148.1562\n",
            "Epoch 31/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 221308.9844\n",
            "Epoch 32/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 218311.2188\n",
            "Epoch 33/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 215123.3906\n",
            "Epoch 34/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 211745.5469\n",
            "Epoch 35/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 208189.8281\n",
            "Epoch 36/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 204414.5781\n",
            "Epoch 37/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 200479.3438\n",
            "Epoch 38/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 196373.4844\n",
            "Epoch 39/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 192026.0156\n",
            "Epoch 40/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 187495.7031\n",
            "Epoch 41/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 182780.4844\n",
            "Epoch 42/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 177868.7812\n",
            "Epoch 43/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 172733.3125\n",
            "Epoch 44/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 167440.4062\n",
            "Epoch 45/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 161917.9375\n",
            "Epoch 46/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 156228.2812\n",
            "Epoch 47/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 150382.8750\n",
            "Epoch 48/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 144348.7656\n",
            "Epoch 49/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 138156.9219\n",
            "Epoch 50/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 131858.0156\n",
            "Epoch 51/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 125383.2266\n",
            "Epoch 52/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 118771.8828\n",
            "Epoch 53/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 112092.7734\n",
            "Epoch 54/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 105314.8438\n",
            "Epoch 55/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 98452.1562\n",
            "Epoch 56/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 91546.2422\n",
            "Epoch 57/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 84652.1484\n",
            "Epoch 58/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 77791.2031\n",
            "Epoch 59/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 70869.1719\n",
            "Epoch 60/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 64091.5586\n",
            "Epoch 61/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 57414.6016\n",
            "Epoch 62/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 50888.3438\n",
            "Epoch 63/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 44591.8867\n",
            "Epoch 64/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 38471.8555\n",
            "Epoch 65/250\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 32632.4629\n",
            "Epoch 66/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 27162.9746\n",
            "Epoch 67/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 22081.1855\n",
            "Epoch 68/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 17438.0293\n",
            "Epoch 69/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 13302.8555\n",
            "Epoch 70/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 9735.2109\n",
            "Epoch 71/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 6795.5137\n",
            "Epoch 72/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 4510.1890\n",
            "Epoch 73/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 2931.6147\n",
            "Epoch 74/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 2050.9021\n",
            "Epoch 75/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1741.8928\n",
            "Epoch 76/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 1670.6864\n",
            "Epoch 77/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1636.2468\n",
            "Epoch 78/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 1595.2705\n",
            "Epoch 79/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 1564.9479\n",
            "Epoch 80/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1529.9521\n",
            "Epoch 81/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1495.7219\n",
            "Epoch 82/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1458.0405\n",
            "Epoch 83/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1427.7847\n",
            "Epoch 84/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 1392.4376\n",
            "Epoch 85/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1356.4546\n",
            "Epoch 86/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1318.4659\n",
            "Epoch 87/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1284.7043\n",
            "Epoch 88/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1250.0924\n",
            "Epoch 89/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1211.6005\n",
            "Epoch 90/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1189.8574\n",
            "Epoch 91/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1156.4897\n",
            "Epoch 92/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1127.5702\n",
            "Epoch 93/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1097.0829\n",
            "Epoch 94/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1066.0225\n",
            "Epoch 95/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 1032.9060\n",
            "Epoch 96/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 999.8931\n",
            "Epoch 97/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 970.9627\n",
            "Epoch 98/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 943.4290\n",
            "Epoch 99/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 915.6025\n",
            "Epoch 100/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 884.5587\n",
            "Epoch 101/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 858.3621\n",
            "Epoch 102/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 829.5159\n",
            "Epoch 103/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 804.7695\n",
            "Epoch 104/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 773.2448\n",
            "Epoch 105/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 747.5583\n",
            "Epoch 106/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 723.1435\n",
            "Epoch 107/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 693.5865\n",
            "Epoch 108/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 671.7714\n",
            "Epoch 109/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 644.5887\n",
            "Epoch 110/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 615.4785\n",
            "Epoch 111/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 592.7398\n",
            "Epoch 112/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 567.7003\n",
            "Epoch 113/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 545.0583\n",
            "Epoch 114/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 520.4230\n",
            "Epoch 115/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 497.6754\n",
            "Epoch 116/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 475.0989\n",
            "Epoch 117/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 450.6780\n",
            "Epoch 118/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 433.4787\n",
            "Epoch 119/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 415.0456\n",
            "Epoch 120/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 395.7059\n",
            "Epoch 121/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 374.9093\n",
            "Epoch 122/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 354.4159\n",
            "Epoch 123/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 336.9301\n",
            "Epoch 124/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 319.4540\n",
            "Epoch 125/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 300.8175\n",
            "Epoch 126/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 283.1828\n",
            "Epoch 127/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 266.6896\n",
            "Epoch 128/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 251.3819\n",
            "Epoch 129/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 237.7410\n",
            "Epoch 130/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 224.3642\n",
            "Epoch 131/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 211.9894\n",
            "Epoch 132/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 196.2307\n",
            "Epoch 133/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 182.3365\n",
            "Epoch 134/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 169.3716\n",
            "Epoch 135/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 157.9190\n",
            "Epoch 136/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 146.8561\n",
            "Epoch 137/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 136.6080\n",
            "Epoch 138/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 126.1662\n",
            "Epoch 139/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 116.3397\n",
            "Epoch 140/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 107.1570\n",
            "Epoch 141/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 99.4893\n",
            "Epoch 142/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 91.2760\n",
            "Epoch 143/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 83.7118\n",
            "Epoch 144/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 76.3514\n",
            "Epoch 145/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 70.6893\n",
            "Epoch 146/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 64.9235\n",
            "Epoch 147/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 59.1999\n",
            "Epoch 148/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 54.2784\n",
            "Epoch 149/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 50.0136\n",
            "Epoch 150/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 46.3731\n",
            "Epoch 151/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 42.6647\n",
            "Epoch 152/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 39.4983\n",
            "Epoch 153/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 37.0755\n",
            "Epoch 154/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 34.7412\n",
            "Epoch 155/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 32.4750\n",
            "Epoch 156/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 30.4122\n",
            "Epoch 157/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 29.9792\n",
            "Epoch 158/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 29.1024\n",
            "Epoch 159/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 27.5910\n",
            "Epoch 160/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 27.5817\n",
            "Epoch 161/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 26.4482\n",
            "Epoch 162/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 26.3619\n",
            "Epoch 163/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 26.1604\n",
            "Epoch 164/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 25.5335\n",
            "Epoch 165/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 25.6389\n",
            "Epoch 166/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 25.1254\n",
            "Epoch 167/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.9809\n",
            "Epoch 168/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 25.1450\n",
            "Epoch 169/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.5582\n",
            "Epoch 170/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4234\n",
            "Epoch 171/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3597\n",
            "Epoch 172/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.5647\n",
            "Epoch 173/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3201\n",
            "Epoch 174/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2378\n",
            "Epoch 175/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2790\n",
            "Epoch 176/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3750\n",
            "Epoch 177/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2595\n",
            "Epoch 178/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.5661\n",
            "Epoch 179/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2350\n",
            "Epoch 180/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2742\n",
            "Epoch 181/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2016\n",
            "Epoch 182/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.8987\n",
            "Epoch 183/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.6950\n",
            "Epoch 184/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3269\n",
            "Epoch 185/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.0241\n",
            "Epoch 186/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1689\n",
            "Epoch 187/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.9008\n",
            "Epoch 188/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3705\n",
            "Epoch 189/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 24.0623\n",
            "Epoch 190/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4005\n",
            "Epoch 191/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1899\n",
            "Epoch 192/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3100\n",
            "Epoch 193/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.7095\n",
            "Epoch 194/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 24.2461\n",
            "Epoch 195/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.5512\n",
            "Epoch 196/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4244\n",
            "Epoch 197/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4095\n",
            "Epoch 198/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1940\n",
            "Epoch 199/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4930\n",
            "Epoch 200/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4516\n",
            "Epoch 201/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.6912\n",
            "Epoch 202/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.0667\n",
            "Epoch 203/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3156\n",
            "Epoch 204/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2916\n",
            "Epoch 205/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.0399\n",
            "Epoch 206/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 24.1896\n",
            "Epoch 207/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1030\n",
            "Epoch 208/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.5477\n",
            "Epoch 209/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3563\n",
            "Epoch 210/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4637\n",
            "Epoch 211/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4293\n",
            "Epoch 212/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2774\n",
            "Epoch 213/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3946\n",
            "Epoch 214/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.7200\n",
            "Epoch 215/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4146\n",
            "Epoch 216/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2240\n",
            "Epoch 217/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4760\n",
            "Epoch 218/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1781\n",
            "Epoch 219/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.0935\n",
            "Epoch 220/250\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 24.3752\n",
            "Epoch 221/250\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 24.2377\n",
            "Epoch 222/250\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 24.2389\n",
            "Epoch 223/250\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 24.7284\n",
            "Epoch 224/250\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 24.4196\n",
            "Epoch 225/250\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 23.9571\n",
            "Epoch 226/250\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 24.4497\n",
            "Epoch 227/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3108\n",
            "Epoch 228/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4191\n",
            "Epoch 229/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3375\n",
            "Epoch 230/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3264\n",
            "Epoch 231/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3864\n",
            "Epoch 232/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 23.9368\n",
            "Epoch 233/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2571\n",
            "Epoch 234/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3809\n",
            "Epoch 235/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1550\n",
            "Epoch 236/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.6255\n",
            "Epoch 237/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3469\n",
            "Epoch 238/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3153\n",
            "Epoch 239/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2767\n",
            "Epoch 240/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.1891\n",
            "Epoch 241/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.4619\n",
            "Epoch 242/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2152\n",
            "Epoch 243/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.3797\n",
            "Epoch 244/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 23.9748\n",
            "Epoch 245/250\n",
            "22/22 [==============================] - 0s 1ms/step - loss: 24.5715\n",
            "Epoch 246/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2768\n",
            "Epoch 247/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 23.9989\n",
            "Epoch 248/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.5522\n",
            "Epoch 249/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.2728\n",
            "Epoch 250/250\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 24.6079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0fc85844d0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "dn5TW9lvNagQ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "D3QfaLFqNsbB",
        "outputId": "297e442e-6182-49dd-fac7-858eb1c65d39"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0fc8537650>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hV9X3v8fd375lhkBlgLjBcBhgQIiIRA8PFqMSoEbRN0cZGbSvEGOl5omlz6ZPapj16Yk7bJCdN43NSc0wkgaTG2MRU6o0QYku0ggzIHYURRAYQhvtNmMv+nj/2b2RnmBszs1kze39ez7OfvfZv/dba31+2mQ9r/dZe29wdERGRlsSiLkBERHouhYSIiLRKISEiIq1SSIiISKsUEiIi0qqcqAvobqWlpV5RURF1GSIivcrq1asPuPug5u0ZFxIVFRVUVVVFXYaISK9iZjtbatfpJhERaZVCQkREWqWQEBGRVmXcnISISFfV19dTU1PD6dOnoy6l2+Xn51NeXk5ubm6H+iskRESaqampobCwkIqKCsws6nK6jbtz8OBBampqGD16dIe20ekmEZFmTp8+TUlJSUYFBICZUVJScl5HSAoJEZEWZFpANDnfcel0U7Bsyz627T/BJUMKGT+kkCH98zP2PxIRkY5SSAT/tbWWRa+e/S7JgL65XFJWyPihhUwY2p8rLy5hZPFFCg4RuSAKCgo4ceJE1GUoJJp8dc5EvvSxS3hz33HefPcYW949zpvvHufpNbtZdCYZHsMH9uWqsSV89JLBfHT8YPJz4xFXLSKSXu2GhJmNABYBZYADj7n7d8zsIeBeoDZ0/Rt3fz5s89fAPUAj8OfuviS0zwa+A8SBH7j7P4b20cCTQAmwGrjL3evMrE947ynAQeB2d3+7G8bdogEX5TJtdDHTRhe/3+buvFV7klffOsAr1QdZsmkfT1XV0C8vzqzLhvAnM0YxeeRAHWGISFq4O1/+8pd54YUXMDP+9m//lttvv529e/dy++23c+zYMRoaGnj00Uf58Ic/zD333ENVVRVmxqc//Wm+8IUvdOn9O3Ik0QB8yd3XmFkhsNrMloZ133b3/5Pa2cwmAHcAlwHDgF+b2QfC6u8CHwNqgFVmttjdNwNfD/t60sy+RzJgHg3Ph919rJndEfrd3pUBny8zY+zgAsYOLuCuKytoaEywcschFq/dw/Mb9vL067v54PABzJ85ht/74FBiMYWFSCb5X/+xic17jnXrPicM68+DH7+sQ32ffvpp1q5dy7p16zhw4ABTp05l5syZPPHEE8yaNYuvfOUrNDY2curUKdauXcvu3bvZuHEjAEeOHOlyre1e3eTue919TVg+DmwBhrexyRzgSXc/4+47gGpgWnhUu/t2d68jeeQwx5L/BL8O+HnYfiFwS8q+FoblnwPXW8T/ZM+Jx7hqbClfv+1yVvzN9Tx8y0RO1TXwuZ++zs2P/JZfbXoX/W64iHSXl19+mTvvvJN4PE5ZWRkf+chHWLVqFVOnTuWHP/whDz30EBs2bKCwsJAxY8awfft2Pve5z/Hiiy/Sv3//Lr//ec1JmFkF8CFgJXAVcL+ZzQWqSB5tHCYZICtSNqvhbKjsatY+neQppiPu3tBC/+FN27h7g5kdDf0PNKtrPjAfYOTIkeczpC7p1yeHu2aM4o+njeTZ9Xv4zq+3Mf/Hq/nIBwbx1TmXMaqk3wWrRUTSo6P/4r/QZs6cyfLly3nuuef41Kc+xRe/+EXmzp3LunXrWLJkCd/73vd46qmnWLBgQZfep8PfkzCzAuAXwOfd/RjJ00EXA1cAe4FvdamSLnD3x9y90t0rBw0653boaRePGXOuGM6vvjCT//n7E1i98zA3fns531++nURCRxUi0nnXXHMNP/vZz2hsbKS2tpbly5czbdo0du7cSVlZGffeey+f+cxnWLNmDQcOHCCRSPCJT3yCr33ta6xZs6bL79+hIwkzyyUZEP/q7k8DuPu+lPXfB54NL3cDI1I2Lw9ttNJ+EBhoZjnhaCK1f9O+aswsBxgQ+vdIOfEYn756NL93+VD+7t838r+f38LybbV865OTGFyYH3V5ItIL3Xrrrbz66qtMmjQJM+Mb3/gGQ4YMYeHChXzzm98kNzeXgoICFi1axO7du7n77rtJJBIA/MM//EOX39/aO38e5gAWAofc/fMp7UPdfW9Y/gIw3d3vMLPLgCdIzkEMA5YB4wADtgLXk/zjvwr4Y3ffZGb/BvwiZeJ6vbv/i5ndB3zQ3f9HmLj+Q3f/ZFv1VlZWek/40SF354nX3uHhZzdT0CeXH8yr5IoRA6MuS0Q6YMuWLVx66aVRl5E2LY3PzFa7e2Xzvh053XQVcBdwnZmtDY+bgW+Y2QYzWw98FPgCgLtvAp4CNgMvAve5e2M4SrgfWEJy8vup0Bfgr4Avmlk1yTmHx0P740BJaP8i8ECH/1eImJnxJ9NHsfj+q+mbF+P2//cqz63fG3VZIiLnpd0jid6mpxxJpDp44gx/9uPVVO08zEMfn8CnrurY3RdFJBo6kjhLN/i7AEoK+vCTz0xn1mVlPPQfm3n85R1RlyQi7ci0f0A3Od9xKSQukPzcOP/3jydz08QhPPzsZn7w2+1RlyQircjPz+fgwYMZFxRNvyeRn9/xC2l076YLKDce45E7P8Sf//R1vvbcFgb3z+cPJg2LuiwRaaa8vJyamhpqa2vb79zLNP0yXUcpJC6w3HiMf77jCg7+4DX+8ql1DOmf/zv3ihKR6OXm5nb4l9synU43RaBPTpzH5k6hvLgv9y6q4u0DJ6MuSUSkRQqJiAy8KI8ffWoaAPc9sYbT9Y0RVyQici6FRIRGllzEt/5oEpv2HOPvn98SdTkiIudQSETshgll3HvNaBa9upPnN+jLdiLSsygkeoAvzx7PpBED+ZtfbqD2+JmoyxEReZ9CogfIjcf41h9dzqkzjTy0eFP7G4iIXCAKiR5i7OBC/uKGcTy3YS8v6LSTiPQQCokeZP7MMVw2rD9/98wmjp6qj7ocERGFRE+SG4/x9U9czsGTZ/jOsm1RlyMiopDoaSYOH8AdU0ew6NW3qd5/IupyRCTLKSR6oC/deAl9c+P67oSIRE4h0QOVFvThc9eP5Tdv7Oe/tmbeDcZEpPdQSPRQn/rwaEaVXMTXX3iDRCKzblcsIr2HQqKHysuJ8fkbxrF57zFe3PRu1OWISJZSSPRgfzBpOGMHF/DtpVtp1NGEiERAIdGDxWPG528Yx7b9J3h2/Z6oyxGRLKSQ6OFunjiU8UMK+edfb9PRhIhccAqJHi4WjiZ2HDjJixs1NyEiF5ZCohf42IQhVJRcxGPL38q4H2YXkZ5NIdELxGPGZ64Zw7qao6zccSjqckQkiygkeonbppRT0i+Px5Zvj7oUEckiColeIj83ztwrK/jNG/vZuu941OWISJZQSPQid105ivzcGD98ZUfUpYhIllBI9CLF/fL4+OXD+PfX93DstH5vQkTSTyHRy/zpjFG8V9/IL9fsjroUEckCColeZtKIgXxw+AB+smKnLocVkbRrNyTMbISZvWRmm81sk5n9RWgvNrOlZrYtPBeFdjOzR8ys2szWm9nklH3NC/23mdm8lPYpZrYhbPOImVlb75Ht/nTGSLbtP8FruhxWRNKsI0cSDcCX3H0CMAO4z8wmAA8Ay9x9HLAsvAa4CRgXHvOBRyH5Bx94EJgOTAMeTPmj/yhwb8p2s0N7a++R1f5g0nAK83P4ycp3oi5FRDJcuyHh7nvdfU1YPg5sAYYDc4CFodtC4JawPAdY5EkrgIFmNhSYBSx190PufhhYCswO6/q7+wpPnj9Z1GxfLb1HVuubF+cTk8t5ceNeDp+si7ocEclg5zUnYWYVwIeAlUCZu+8Nq94FysLycGBXymY1oa2t9poW2mnjPZrXNd/MqsysqrY2O37J7ZOVI6hvdBav091hRSR9OhwSZlYA/AL4vLsfS10XjgDSOova1nu4+2PuXunulYMGDUpnGT3GhGH9mTC0Pz9fXdN+ZxGRTupQSJhZLsmA+Fd3fzo07wunigjP+0P7bmBEyubloa2t9vIW2tt6DyF5q44Nu4/yxrvH2u8sItIJHbm6yYDHgS3u/k8pqxYDTVcozQOeSWmfG65ymgEcDaeMlgA3mllRmLC+EVgS1h0zsxnhveY221dL7yHAnCuGkRMzfqGjCRFJk44cSVwF3AVcZ2Zrw+Nm4B+Bj5nZNuCG8BrgeWA7UA18H/gsgLsfAh4GVoXHV0Mboc8PwjZvAS+E9tbeQ4CSgj5cN34wv3x9D/WNiajLEZEMlNNeB3d/GbBWVl/fQn8H7mtlXwuABS20VwETW2g/2NJ7yFm3TSnnV5v3sXxrLddf2uK8vohIp+kb173ctZcMZkDfXP5DVzmJSBooJHq5vJwYN00cwtLN+3ivrjHqckQkwygkMsDHJw3jZF0jL72pi79EpHspJDLAjDEllBb04dn1OuUkIt1LIZEB4jHj9z44hGVb9nPiTEPU5YhIBlFIZIjfnzSMMw0Jfr15X9SliEgGUUhkiCkjixg6IF9XOYlIt1JIZIhYzLhp4lB+u+2ATjmJSLdRSGSQWZeVUdeY4D91lZOIdBOFRAaprCimpF8ev9qkeQkR6R4KiQwSjxk3XFrGS2/sp65B93ISka5TSGSYWRPLOH6mgf9+60DUpYhIBlBIZJgPX1xKv7w4S3TKSUS6gUIiw+Tnxrn2ksEs3byPRCKtPxYoIllAIZGBbrysjAMnzvD6rsNRlyIivZxCIgNde8lg4jHjN2/oUlgR6RqFRAYa0DeXKaOK+M0btVGXIiK9nEIiQ10/fjBb9h5j79H3oi5FRHoxhUSGum78YABe0tGEiHSBQiJDjR1cQHlRX81LiEiXKCQylJlx3fjBvFJ9gNP1+llTEekchUQG++j4wbxX38jKHYeiLkVEeimFRAa7ckwJ+bkxXtIpJxHpJIVEBsvPjXPlmBKWb9XktYh0jkIiw10zbhDbD5yk5vCpqEsRkV5IIZHhrhlXCsDL23RXWBE5fwqJDDd2cAFl/fvw22qFhIicP4VEhjMzrh47iFeqD9Cou8KKyHlSSGSBmR8o5cipejbtORp1KSLSy7QbEma2wMz2m9nGlLaHzGy3ma0Nj5tT1v21mVWb2ZtmNiulfXZoqzazB1LaR5vZytD+MzPLC+19wuvqsL6iuwadba4am5yX+K3mJUTkPHXkSOJHwOwW2r/t7leEx/MAZjYBuAO4LGzzL2YWN7M48F3gJmACcGfoC/D1sK+xwGHgntB+D3A4tH879JNOKC3ow6VD+2vyWkTOW7sh4e7LgY5+ZXcO8KS7n3H3HUA1MC08qt19u7vXAU8Cc8zMgOuAn4ftFwK3pOxrYVj+OXB96C+dcM24Uqp2HuJUXUPUpYhIL9KVOYn7zWx9OB1VFNqGA7tS+tSEttbaS4Aj7t7QrP139hXWHw39z2Fm882sysyqamv1xbGWXD22lPpG1y06ROS8dDYkHgUuBq4A9gLf6raKOsHdH3P3SnevHDRoUJSl9FjTRheTlxPTKScROS+dCgl33+fuje6eAL5P8nQSwG5gRErX8tDWWvtBYKCZ5TRr/519hfUDQn/phPzcONMqivntNh1piUjHdSokzGxoystbgaYrnxYDd4Qrk0YD44DXgFXAuHAlUx7Jye3F7u7AS8BtYft5wDMp+5oXlm8DfhP6SyddPa6UrftOsO/Y6ahLEZFeIqe9Dmb2U+BaoNTMaoAHgWvN7ArAgbeBPwNw901m9hSwGWgA7nP3xrCf+4ElQBxY4O6bwlv8FfCkmX0NeB14PLQ/DvzYzKpJTpzf0eXRZrmrw6Wwr1Qf4A8nl0dcjYj0BpZp/zivrKz0qqqqqMvokRIJ50MPL+XGCWV8848mRV2OiPQgZrba3Subt+sb11kkFjOmjy5mxQ5N7YhIxygkssyVF5ew69B7unW4iHSIQiLLzBiT/KrJyu36voSItE8hkWUuKStk4EW5rNiuU04i0j6FRJZpmpd4VSEhIh2gkMhCM8aUUHP4PXYd0ryEiLRNIZGF3p+X0H2cRKQdCoksdElZIUWalxCRDlBIZKHkvEQJr76lkBCRtikkstSMMcXsPqJ5CRFpm0IiS824ODkvoVNOItIWhUSW+sDgpnkJTV6LSOsUElkqFjNmjCnRkYSItEkhkcWmj9a8hIi0TSGRxaaOLgZg9c7DEVciIj2VQiKLjR/Sn4I+Oax6W/MSItIyhUQWi8eMyaOKFBIi0iqFRJabOqqIrftOcORUXdSliEgPpJDIcpqXEJG2KCSy3KTygeTGjVVvKyRE5FwKiSzXNy/OxOEDNC8hIi1SSAjTKopZX3OE0/WNUZciIj2MQkKorCimvtFZX3M06lJEpIdRSAhTRhUB6JSTiJxDISEU98tj7OAChYSInEMhIQBMrShm9c7DNCY86lJEpAdRSAgAUyuKOH66ga37jkddioj0IAoJAZJHEgBVOuUkIikUEgJAeVFfhvTP5zV9qU5EUigkBAAzo7KiiFU7DuGueQkRSWo3JMxsgZntN7ONKW3FZrbUzLaF56LQbmb2iJlVm9l6M5ucss280H+bmc1LaZ9iZhvCNo+YmbX1HpI+UyuKeffYaXYfeS/qUkSkh+jIkcSPgNnN2h4Alrn7OGBZeA1wEzAuPOYDj0LyDz7wIDAdmAY8mPJH/1Hg3pTtZrfzHpImlRXJj6RKp5xEJGg3JNx9OdB8NnMOsDAsLwRuSWlf5EkrgIFmNhSYBSx190PufhhYCswO6/q7+wpPnuNY1GxfLb2HpMn4If0p7JPDa5q8FpGgs3MSZe6+Nyy/C5SF5eHArpR+NaGtrfaaFtrbeo9zmNl8M6sys6ra2tpODEcg5UeIdigkRCSpyxPX4QggrTOd7b2Huz/m7pXuXjlo0KB0lpLxplYUsW2/foRIRJI6GxL7wqkiwvP+0L4bGJHSrzy0tdVe3kJ7W+8haTRlVPL7Emve0byEiHQ+JBYDTVcozQOeSWmfG65ymgEcDaeMlgA3mllRmLC+EVgS1h0zsxnhqqa5zfbV0ntIGl0xYiA5MdPktYgAkNNeBzP7KXAtUGpmNSSvUvpH4CkzuwfYCXwydH8euBmoBk4BdwO4+yEzexhYFfp91d2bTnx/luQVVH2BF8KDNt5D0qhvXpzLhg9QSIgI0IGQcPc7W1l1fQt9Hbivlf0sABa00F4FTGyh/WBL7yHpVzmqiJ+s2EldQ4K8HH3fUiSb6S+AnKNyVBFnGhJs3KMfIRLJdgoJOceU979Up0thRbKdQkLOMbgwn1ElF2leQkQUEtKyKaOKWL3zsG72J5LlFBLSoqkVxRw8WcfbB09FXYqIREghIS2qHJWcl9DvXotkN4WEtOjiQQUM6JvLas1LiGQ1hYS0KBYzKkcVUbVTRxIi2UwhIa2aUlHEW7UnOXRSN/sTyVYKCWlVZbjZ3+qdOuUkkq0UEtKqy8sHkBeP6ZSTSBZTSEir8nPjTBzeX1+qE8liCglpU2VFMRtqjnK6vjHqUkQkAgoJaVPlqCLqGhNs3K2b/YlkI4WEtGnK+1+q0yknkWykkJA2lRT0YUxpP1Zr8lokKykkpF2VFbrZn0i2UkhIuypHFXP4VD1v1Z6MuhQRucAUEtIu/QiRSPZSSEi7xpT2o7hfHlX65rVI1lFISLvM7P0fIRKR7KKQkA6pHFXEjgMnqT1+JupSROQCUkhIh1RW6GZ/ItlIISEdMnF4f/JyYvq+hEiWUUhIh/TJiTOpfIC+eS2SZRQS0mGVFcVs2qOb/YlkE4WEdFjlqCLqG521u45EXYqIXCAKCemwyopizGDlds1LiGQLhYR02IC+uVw6pD8rdxyMuhQRuUC6FBJm9raZbTCztWZWFdqKzWypmW0Lz0Wh3czsETOrNrP1ZjY5ZT/zQv9tZjYvpX1K2H912Na6Uq903fQxxax55zB1DYmoSxGRC6A7jiQ+6u5XuHtleP0AsMzdxwHLwmuAm4Bx4TEfeBSSoQI8CEwHpgEPNgVL6HNvynazu6Fe6YLpo0s4XZ9gfY3mJUSyQTpON80BFoblhcAtKe2LPGkFMNDMhgKzgKXufsjdDwNLgdlhXX93X+HJe1QvStmXRGT66OSX6lZs1yknkWzQ1ZBw4FdmttrM5oe2MnffG5bfBcrC8nBgV8q2NaGtrfaaFtrPYWbzzazKzKpqa2u7Mh5pR1G/PMYPKWTlDk1ei2SDrobE1e4+meSppPvMbGbqynAEkPZfqnH3x9y90t0rBw0alO63y3rTRxezeudh6hs1LyGS6boUEu6+OzzvB35Jck5hXzhVRHjeH7rvBkakbF4e2tpqL2+hXSI2fUwJp+oa2bD7aNSliEiadTokzKyfmRU2LQM3AhuBxUDTFUrzgGfC8mJgbrjKaQZwNJyWWgLcaGZFYcL6RmBJWHfMzGaEq5rmpuxLIjRN8xIiWSOnC9uWAb8MV6XmAE+4+4tmtgp4yszuAXYCnwz9nwduBqqBU8DdAO5+yMweBlaFfl9196YT3p8FfgT0BV4ID4lYaUEfxg0uYMX2Q3z22qirEZF06nRIuPt2YFIL7QeB61tod+C+Vva1AFjQQnsVMLGzNUr6XDW2lJ+t2sWZhkb65MSjLkdE0kTfuJZOuWpsKe/VN/L6O/q+hEgmU0hIp0wfU0w8ZrxSfSDqUkQkjRQS0in983O5vHwALyskRDKaQkI67eqxpazbdYRjp+ujLkVE0kQhIZ121dhSEg4r3tKlsCKZSiEhnfahkQPpmxvXvIRIBlNISKf1yYkzbXQxr+hIQiRjKSSkS64eW0r1/hPsPfpe1KWISBooJKRLPnJJ8oaKv3ljfzs9RaQ3UkhIl4wbXMCI4r4s26KQEMlECgnpEjPj+vFlvFJ9gPfqGqMuR0S6mUJCuuyGS8s405DQF+tEMpBCQrps2uhiCvvksGzLvqhLEZFuppCQLsvLiTHzA4NY9sZ+Eom0/xChiFxACgnpFteNH0zt8TP6tTqRDKOQkG7x0fGDiRk65SSSYRQS0i2K++UxtaKY5zbsJfn7UiKSCRQS0m0+PmkYb9We5I13j0ddioh0E4WEdJubJg4hHjOeXb8n6lJEpJsoJKTblBT04cMXl/DM2j26ykkkQygkpFvdNqWcmsPvsWKH7gwrkgkUEtKtZl02hML8HJ5atSvqUkSkGygkpFvl58aZc8UwXtj4LodP1kVdjoh0kUJCut1dMyo405DgidfeiboUEekihYR0u0uGFHLNuFIW/vfb1DUkoi5HRLpAISFp8ZlrxrD/+Bn+bbXmJkR6M4WEpMXMcaVUjiriO7/exqm6hqjLEZFOUkhIWpgZD9w0nv3Hz/Ddl6qjLkdEOkkhIWlTWVHMbVPKefQ/32LNO4ejLkdEOkEhIWn14McnMGxgX+YvWk31/hNRlyMi56nHh4SZzTazN82s2sweiLoeOT+F+bn86O6pANz6L6/w3ZeqWbfrCDsPnmTPkfc4cOIMx07Xc7q+UbfyEOmBrCff1tnM4sBW4GNADbAKuNPdN7e2TWVlpVdVVV2gCqWjdh48yYOLN/Gfb9a22S8eM3KaHvEYuXEjJxYjJ27kxmPkxIx4LCzHjdywLiceI7fZupxY2L5pHy3u8+xy87am53h4n3jYf8wgFjPi1vTaiMUgbvZ++/ttTa9Dv3hKeyz0a9qnmV2gT0PkXGa22t0rm7fnRFHMeZgGVLv7dgAzexKYA7QaEtIzjSrpx4/unsY7B0+xee8xTtU1UNeQoK4xQV1DgjMNyeeGRIKGRqch4TQ0JqgPzw2NfnY55bk+bH+yrpGGxgSNoS3Z5+xyfViX3E+Cnvhvo5gRwiU1gJKBZJwNkeRy01Jy+WwbGPZ+G6nbNa23s33O7s/e74/xO+8nvcff3/pBpo0u7tZ99vSQGA6kXmhfA0xv3snM5gPzAUaOHHlhKpNOGVlyESNLLoq6jGZhcm6oNDQmqG/0ZGiFdQ2JBIkEJNxpdCeRcBoTTsJDW8JTnkmuD689PDemtCfe3wc0emqfs+2J0K8p1JzkclPGJdtT1vvZPsk1Z9uaGpJt3mx90/ahZw8MUWlfvz7xbt9nTw+JDnH3x4DHIHm6KeJypBdInjrq/v9DiWSanj5xvRsYkfK6PLSJiMgF0NNDYhUwzsxGm1kecAewOOKaRESyRo8+3eTuDWZ2P7AEiAML3H1TxGWJiGSNHh0SAO7+PPB81HWIiGSjnn66SUREIqSQEBGRVikkRESkVQoJERFpVY++d1NnmFktsLOTm5cCB7qxnN5AY84e2ThujbnjRrn7oOaNGRcSXWFmVS3d4CqTaczZIxvHrTF3nU43iYhIqxQSIiLSKoXE73os6gIioDFnj2wct8bcRZqTEBGRVulIQkREWqWQEBGRVikkAjObbWZvmlm1mT0QdT3pYmZvm9kGM1trZlWhrdjMlprZtvBcFHWdXWFmC8xsv5ltTGlrcYyW9Ej43Neb2eToKu+8Vsb8kJntDp/1WjO7OWXdX4cxv2lms6KpumvMbISZvWRmm81sk5n9RWjP2M+6jTGn77P28LOJ2fwgeRvyt4AxQB6wDpgQdV1pGuvbQGmztm8AD4TlB4CvR11nF8c4E5gMbGxvjMDNwAskf9Z5BrAy6vq7ccwPAX/ZQt8J4b/xPsDo8N9+POoxdGLMQ4HJYbkQ2BrGlrGfdRtjTttnrSOJpGlAtbtvd/c64ElgTsQ1XUhzgIVheSFwS4S1dJm7LwcONWtubYxzgEWetAIYaGZDL0yl3aeVMbdmDvCku59x9x1ANcn/D/Qq7r7X3deE5ePAFmA4GfxZtzHm1nT5s1ZIJA0HdqW8rqHt/+F7Mwd+ZWarzWx+aCtz971h+V2gLJrS0qq1MWb6Z39/OLWyIOU0YsaN2cwqgA8BK8mSz7rZmCFNn7VCIvtc7e6TgZuA+8xsZupKTx6jZvR10dkwxuBR4GLgCmAv8K1oy0kPMysAfgF83t2Ppa7L1M+6hTGn7bNWSCTtBkakvC4PbRnH3XeH5/3AL0keeu5rOuwOz/ujqzBtWhtjxn727r7P3RvdPQF8n7OnGTJmzGaWSzPAQyMAAAEhSURBVPKP5b+6+9OhOaM/65bGnM7PWiGRtAoYZ2ajzSwPuANYHHFN3c7M+plZYdMycCOwkeRY54Vu84BnoqkwrVob42JgbrjyZQZwNOVURa/W7Hz7rSQ/a0iO+Q4z62Nmo4FxwGsXur6uMjMDHge2uPs/pazK2M+6tTGn9bOOera+pzxIXvmwleTs/1eiridNYxxD8kqHdcCmpnECJcAyYBvwa6A46lq7OM6fkjzkrid5Dvae1sZI8kqX74bPfQNQGXX93TjmH4cxrQ9/LIam9P9KGPObwE1R19/JMV9N8lTSemBteNycyZ91G2NO22et23KIiEirdLpJRERapZAQEZFWKSRERKRVCgkREWmVQkJERFqlkBARkVYpJEREpFX/Hx2uYalAfVFIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KRrL60dMNzfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}